{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58e1413c",
   "metadata": {},
   "source": [
    "# Notebook 2-5: HMM Task Analysis\n",
    "\n",
    "In this notebook, we will cover:\n",
    "1. **Epoch state time courses and create constrasts**: We will epoch state time courses with task events and create contrasts.\n",
    "2. **Evoked network responses**: We will perform statistical tests and visualise evoked network responses for different contrasts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c909e1",
   "metadata": {},
   "source": [
    "# 1. Epoch state time courses\n",
    "We will epoch the state time courses with task events. Note that the state time courses are inferred from the HMM, which has no knowledge of the task structure in the data. Again, we will start with loading the state probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0653a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from osl_dynamics.inference import modes\n",
    "\n",
    "alp = pickle.load(open(\"results/inf_params/alp.pkl\", \"rb\"))\n",
    "stc = modes.argmax_time_courses(alp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6802b83",
   "metadata": {},
   "source": [
    "We will also need to load the original `.fif` files to get the task event onsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12222e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "parc_files = sorted(glob(\"wakeman-henson/*/*_sflip_lcmv-parc-raw.fif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d46e4",
   "metadata": {},
   "source": [
    "Sanity check for same number of sessions in state time courses and original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d4520",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(stc), len(parc_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1a80e7",
   "metadata": {},
   "source": [
    "Now we extract the task events and epoch the state time courses. Please take some time to go through the code and make sure you understand what each step does. In short, we convert into `mne.io.Raw` objects and use the `mne.Epochs` API to extract the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a9a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "# Event IDs\n",
    "new_event_ids = {\"famous\": 1, \"unfamiliar\": 2, \"scrambled\": 3}\n",
    "old_event_ids = {\n",
    "    \"famous\": [5, 6, 7],\n",
    "    \"unfamiliar\": [13, 14, 15],\n",
    "    \"scrambled\": [17, 18, 19],\n",
    "}\n",
    "\n",
    "visual_all = []\n",
    "faces_vs_scrambled = []\n",
    "\n",
    "# Loop through sessions\n",
    "for s, p in zip(stc, parc_files):\n",
    "\n",
    "    # Create an MNE raw object\n",
    "    raw = modes.convert_to_mne_raw(s, p, n_embeddings=15)\n",
    "\n",
    "    # Find events\n",
    "    events = mne.find_events(raw, min_duration=0.005, verbose=False)\n",
    "    for old_event_codes, new_event_codes in zip(old_event_ids.values(), new_event_ids.values()):\n",
    "        events = mne.merge_events(events, old_event_codes, new_event_codes)\n",
    "\n",
    "    # Epoch\n",
    "    epochs = mne.Epochs(raw, events, new_event_ids, tmin=-0.1, tmax=1.0)\n",
    "    print(epochs)\n",
    "\n",
    "    # First-level analysis\n",
    "    # Get averaged state activation for each stimulus\n",
    "    famous = epochs[\"famous\"].get_data(picks=\"misc\").mean(axis=0)\n",
    "    unfamiliar = epochs[\"unfamiliar\"].get_data(picks=\"misc\").mean(axis=0)\n",
    "    scrambled = epochs[\"scrambled\"].get_data(picks=\"misc\").mean(axis=0)\n",
    "\n",
    "    # Total response for each state to all stimuli (famous faces, unfamiliar faces, scrambled faces)\n",
    "    visual_all.append((famous + unfamiliar + scrambled) / 3)\n",
    "\n",
    "    # Difference in state response for faces vs scrambled\n",
    "    faces_vs_scrambled.append(famous + unfamiliar - 2 * scrambled)\n",
    "\n",
    "visual_all = np.array(visual_all)\n",
    "faces_vs_scrambled = np.array(faces_vs_scrambled)\n",
    "\n",
    "# Get time axis and correct for the trigger delay\n",
    "t = np.copy(epochs.times)\n",
    "t -= 34e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c40f119",
   "metadata": {},
   "source": [
    "Next we will do a baseline correction to remove ongoing neural activity before the task onset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260da16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_all -= np.mean(visual_all[..., t < 0], axis=-1, keepdims=True)\n",
    "faces_vs_scrambled -= np.mean(faces_vs_scrambled[..., t < 0], axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1126a6",
   "metadata": {},
   "source": [
    "Now we can use the permutation test on the maximum statistic to test for periods of significant evoked network responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b61d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osl_dynamics.analysis import statistics\n",
    "\n",
    "visual_all_pvalues = statistics.evoked_response_max_stat_perm(visual_all, n_perm=1000)\n",
    "faces_vs_scrambled_pvalues = statistics.evoked_response_max_stat_perm(faces_vs_scrambled, n_perm=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8059b067",
   "metadata": {},
   "source": [
    "Find the group-level response for visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8422c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_all_mean = np.mean(visual_all, axis=0)\n",
    "faces_vs_scrambled_mean = np.mean(faces_vs_scrambled, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cb93ea",
   "metadata": {},
   "source": [
    "2. **Evoked network responses**\n",
    "In this section we will visualise the analysis we just performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a847c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osl_dynamics.utils import plotting\n",
    "\n",
    "fig, ax = plotting.plot_evoked_response(\n",
    "    t,\n",
    "    visual_all_mean.T,\n",
    "    visual_all_pvalues.T,\n",
    "    significance_level=0.1,  # normally would use 0.05\n",
    "    labels=[f\"State {i}\" for i in range(1, 7)],\n",
    "    x_label=\"Time (s)\",\n",
    "    y_label=\"State Activation\",\n",
    "    title=\"visual_all\",\n",
    ")\n",
    "fig.savefig(\"plots/network_response_0.png\")\n",
    "\n",
    "fig, ax = plotting.plot_evoked_response(\n",
    "    t,\n",
    "    faces_vs_scrambled_mean.T,\n",
    "    faces_vs_scrambled_pvalues.T,\n",
    "    significance_level=0.1,  # normally would use 0.05\n",
    "    labels=[f\"State {i}\" for i in range(1, 7)],\n",
    "    x_label=\"Time (s)\",\n",
    "    y_label=\"State Activation\",\n",
    "    title=\"faces_vs_scrambled\",\n",
    ")\n",
    "fig.savefig(\"plots/network_response_1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee320281",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "- When you have lots of sessions, how do you speed up the statistical tests?\n",
    "- Can you calculate, test, and visualise the group-level response for famous vs non-famous faces?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
